{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187608ea",
   "metadata": {},
   "source": [
    "# Authenticating with S3 Bucket: Reading Data Objects into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770fe0d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a1821",
   "metadata": {},
   "source": [
    "This notebook was created by [Jupyter AI](https://github.com/jupyterlab/jupyter-ai) with the following prompt:\n",
    "\n",
    "> /generate create a notebook that authenticates to an s3 bucket reads the data objects into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1457e8",
   "metadata": {},
   "source": [
    " The Jupyter notebook in question is a comprehensive guide on how to authenticate with an S3 bucket using AWS SDK or environment variables. It then shows how to navigate and interact with this bucket, specifically focusing on reading data objects into a pandas DataFrame for further analysis. Key steps include installing necessary libraries, setting up AWS credentials, creating an S3 client, listing objects in the bucket, selecting and reading data objects, and performing basic exploratory data analysis on the resulting DataFrame. This notebook serves as a practical resource for users who wish to leverage cloud-based storage and data processing capabilities to work with their data effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1f506",
   "metadata": {},
   "source": [
    "## Set Up AWS Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a89e34",
   "metadata": {},
   "source": [
    " The provided code is nearly correct, but it includes placeholders for the AWS access key and secret key. In a real-world scenario, you should never hardcode these values directly into your scripts. Instead, use secure methods to store and retrieve them. Here's an improved version of the script that uses environment variables to store the credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Set up AWS Credentials using environment variables\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_ACCESS_KEY'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_SECRET_KEY'\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test AWS S3 connection by listing all the buckets in your account\n",
    "try:\n",
    "    for bucket in s3.buckets.all():\n",
    "        print(bucket.name)\n",
    "except NoCredentialsError:\n",
    "    print(\"No AWS credentials found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfb715",
   "metadata": {},
   "source": [
    "## Create S3 Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb46fd5",
   "metadata": {},
   "source": [
    " import boto3\n",
    "\n",
    "   # Replace the access key and secret key with your actual credentials\n",
    "   ACCESS_KEY = 'your-access-key'\n",
    "   SECRET_KEY = 'your-secret-key'\n",
    "\n",
    "   # Create an S3 client object using the provided credentials\n",
    "   s3_client = boto3.client('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e0a7c",
   "metadata": {},
   "source": [
    "The improvements made to the code include adding comments for clarity and specifying that the AWS access key ID and secret access key should be replaced with the actual credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adbe163",
   "metadata": {},
   "source": [
    "## List Objects in the Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40073290",
   "metadata": {},
   "source": [
    " The code provided is already correct and works as intended. However, I have added error handling to make the code more robust. Here's the improved version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6add84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects_in_bucket(bucket_name):\n",
    "    # Define S3 resource\n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    try:\n",
    "        bucket = s3.Bucket(bucket_name)\n",
    "        objects = bucket.objects.all()\n",
    "\n",
    "        # Print out each object key\n",
    "        for obj in objects:\n",
    "            print(obj.key)\n",
    "    except NoCredentialsError:\n",
    "        print(\"No AWS credentials found\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ecf8c8",
   "metadata": {},
   "source": [
    "# Specify your bucket name and call the function\n",
    "bucket_name = 'your-bucket-name'\n",
    "list_objects_in_bucket(bucket_name)\n",
    "This code adds a try/except block to handle any errors that might occur when trying to list the objects in the specified S3 bucket. If no AWS credentials are found, it will print an error message. For other exceptions, it will print the exception itself. This makes debugging easier and provides more useful feedback in case of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7d644",
   "metadata": {},
   "source": [
    "## Select and Read Data Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed95ed2",
   "metadata": {},
   "source": [
    " import pandas as pd\n",
    "   import boto3\n",
    "   from io import BytesIO\n",
    "\n",
    "   s3 = boto3.client('s3')\n",
    "\n",
    "   bucket = 'your-bucket'\n",
    "   key = 'path/to/your/object.csv'\n",
    "\n",
    "   obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "   data = obj['Body'].read()\n",
    "\n",
    "   # Use BytesIO instead of StringIO to handle binary data directly from the object\n",
    "   data_file = BytesIO(data)\n",
    "\n",
    "   df = pd.read_csv(data_file, delimiter=',')  # adjust parameters as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f45bb",
   "metadata": {},
   "source": [
    "## Explore DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65465f21",
   "metadata": {},
   "source": [
    " import pandas as pd\n",
    "\n",
    "   def explore_dataframe(df):\n",
    "       # Display data frame shape\n",
    "       print(\"Shape of DataFrame:\", df.shape)\n",
    "\n",
    "       # Display first few rows of the DataFrame\n",
    "       print(\"\\nFirst few rows of the DataFrame:\")\n",
    "       display(df.head())\n",
    "\n",
    "       # Check for missing values in the DataFrame\n",
    "       print(\"\\nMissing values in the DataFrame:\")\n",
    "       display(df.isnull().sum())\n",
    "\n",
    "       # Summary statistics for numeric columns in the DataFrame\n",
    "       print(\"\\nSummary statistics for numeric columns:\")\n",
    "       display(df.describe(include=[pd.np.number]))\n",
    "\n",
    "   explore_dataframe(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
